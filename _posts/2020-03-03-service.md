---
layout: post
title: 안정적인 서비스 운영
comments: true
---
# 스토리지 스케일링
## 분산 파일 시스템
* 복제본 수를 일률적으로 적용할 필요가 없음
    * 요청이 많은 파일은 복제본 수를 늘리고 
    * 보존시한이 얼마 남지 않은 파일은 복제수 줄이고
        * 대용량 파일 같은 경우

* 중복 파일 처리(ex. 어둠의 경로로 보낸 영상들이 메일서비스에 쌓이는 경우)
    * 그냥 둘 것인가
    * 줄일 것인가

## 사용성에 따라
### 단위 디스크 크기와 서버의 디스크 베이 갯수
* 파일을 쌓아두기만 하는 아카이빙 용도인지
    * 용량이 큰 디스크를
* 거의 전 파일에 거쳐 IO가 발생하는지
    * 빠른 디스크(혹은 SSD)를 많이 꽂아서
* 최근 파일만 주로 사용하는지
    * 최근 파일은 작은 디스크(혹은 SSD)로 구성한 서버를 사용하고
    * 시간이 지난 파일은 용량이 큰 서버로 이전

# 장비가 늘어나면서 고려해야 할 것들
## 빠른 배포
### 배포가 번거로운 일이 되면 안됨
* 페이스북
    * BitTorrent 이용
    * 사이트 업데이트에 15~30분 소요
    * 마이너 업데이트는 매일
    * 메이저 업데이트는 매주 한 번

## 빠른 롤백
### 빠른 배포보다 중요!
### 롤백 기준 사전 정의 필수
* 배포 장애시 우왕좌왕하면 안됨
* 즉각 해결을 못한다면 미련없이 롤백
    * "10분이면 고칠 것 같아요" 이런 말 믿지 말 것!
* 어떤 절차로 해야 하는지 생각해놔야함

### `배포 전에, 롤백 때 필요한 작업 미리 준비`
* 롤백 때 사용할 버전/패키지를 미리 준비
* 롤백 결정 후, 이런 저런 스크립트 만들면 때는 늦음
* 엔터 한 번으로 롤백이 되도록

### `롤백이 예상되는(?) 배포의 경우`
* 디비 변경이 있어도 롤백이 가능하도록 개발
* QA를 정상 배포, 롤백 후 상태 두 가지에 대해 진행

## 배포 중...
### 배포하고 있는 중, UI가 깨지는 현상
* CSS, 이미지를 선배포하고 웹 응용 파일을 배포
    * 새 서버로 들어갔다가 구 서버로 가는 경우, 반대의 경우 등등

# 장비가 늘면서 생각할 고민들
## 설정 관리
### 모든 장비의 설정 내용이 같은가
* 설정 값을 바꿔가며 테스트 한 다음 그대로 방치하는 경우가 있음

### 배포
* 바이너리 배포 시 함께?
* 설정은 따로 리포지토리 관리?
* 별도의 Configuration 서버를 두고 관리하는 것으로 해결하기도 함


# 속도
## 두 배 빨라진다면
### 50% 하드웨어로 커버

# 속도 개선
## 제일 첫 번째 작업은 프로파일링
### 절대로 감에 의존하지 말 것
### 어디가 느린지 파악하는 것이 우성
* 어느 부분이 실제 병목인지, 병목 지점을 찾자

## 해결책
### 캐쉬: Redis, ...
*  각 레이어별 적용 가능
    *  DB에서, WAS에서, 웹 서버에서 각각 캐쉬 가능

* 저장 방식
    * 사용할 결과를 그대로 저장
        * 빠르나 많은 메모리
    * 구조화하여 저장
        * 조금 느리지만 보다 효율적인 메모리 사용

### 캐쉬: `지역성`을 고려해서 설계
* 시간적 지역성
    * 한번 읽은 데이터를 곧 다시 읽을 수 있다.
    * LRU
* 공간적 지역성
    * 읽은 곳 근처의 데이터를 접근하는 경우가 있다.
    * 프리패치(Prefetch)
    * ex)페이지 단위로 이루어진 서비스에서 다음 페이지를 로딩
    * ex2)안드로이드, 메일 서비스 등에서 미리 로딩

### 증설
* 사용자가 늘었거나, 기능이 추가되어서 정말 증설이 필요할 수도 있음
* 증설은 죄가 아님

### `정책 변경`
**예) 조회수가 꼭 정확해야하나?**
  * 빠른 공유 저장소(redis)에 기록하되, 일정 시간마다 디비에 기록
  * 디비에 기록하기 전에 저장소가 비정상 종료된다면 일부 조회수는 유실
      * 이런 것을 정책으로 허용하느냐 마냐에 따라 구조가 달라짐
  * 디비 기록 주기가 1분이고, 분당 1,000번 조회를 할 경우
      * 정책과 약간의 코드만으로 디비 UPDATE를 분당 1,000회에서 단 1회로 줄일 수 있음

* WWDC, GoogleIO 티켓 구매
    * 최근 몇 년 초단기간에 매진을 기록
    * 하지만 사이트는 먹통
    * 결국, 추첨해서 티켓 구매 기회를 주는 것으로 `변경`

# 스토리지 속도
## 메모리

## 디스크 개수
### T1 * 1 vs 100G * 10
* 많은 것이 더 빠를 수도 있음 (RAID)

## RAID 컨트롤러
### 정책
* 배터리 충전 중에는 디스크에 바로 쓰기(Battery Backup Write Cache)
    * 전원 공급이 갑자기 끊길 때 쓰기 유실을 최소화 하기 위한 드라이버 정책(조정 가능)
* 하지만 이로 인해 디비 같은 경우 서비스 품질이 급락

# 품질 관리
## 웹, WAS
### URI의 빈도와 각 URI별 응답속도 관리
* 최소한 평균과 표준편차 두 지표를 관리

### 구간별 처리 속도 관리
* 주요 기능의 경우, URI 하나의 응답 속도를 더 쪼개서 내부 로직별 처리 속도를 기록
* http://zipkin.io/

# 메일 발송
## 생각보다 관리할 것이 많음
### 한 통 발송은 쉽지만,
* 책 예제 따라하면 됨

### 다량 발송은 손이 많이 감
* 코드의 문제가 아니라 운영 문제
    * KISA 화이트IP 등록
    * (업계가 21세기답계 돌아가지는 않음...)
* 장애: COS 발송 장애 등
    * SPF(발송IP등록), 수신 서버 정책 등 여러 변수
        * `SPF`: 발송자 사칭의 경우를 막기 위해 등록
        * 원래 서비스의 메일 서버의 IP를 모두 등록, 해당 서버가 맞는 지 확인 후 스팸처리

## dove, 메일발송플랫폼
### SMTP 서버 풀
### 지정한 IP에 발송하면 알아서 운영성 작업 처리
* 발송IP가 막히면 자동으로 IP를 바꿔서 발송

### 신청

# 자동화
## 신규 서버 설치
### 장비를 받아, 10분 내에 설치할 수 있도록
* 초기서버용 배포 스크립트 등
### 방화벽 오픈 등이 빠른 대응에 걸림돌
* 놓치는 경우가 많음
* 애당초 C클래스 단위로 관리

## 일상적인 응용 배포

## 자동 복구
### 장애 시 루틴하게 하는 작업
* 예, 프로세스 재구동 등을 특정 조건일 때 자동으로 수행하도록
* ex) 이중화가 안된 Redis 서버 죽었을 때
    * 장애가 여부도 모를정도로(그러면 안되지만) 자동적으로 복구
* 실제로 문제를 해결하기까지 `시간`을 벌어주는 일

# 배치 작업
## 필요한 기본 인프라
### 실패시 알림
* 왜 실패했는지 알아야함
### 과거 작업 이력 조회
* 시간이 과거에는 어느정도 걸렸는데 지금은 어느정도 걸리는지 비교할 수 있어야 함
### 여러 서버 묶어서 실행
### 젠킨스
* 젠킨스를 이용하여 배치작업 가능

# 로그 처리
## 수집
### 주기는?
* 실시간
    * Scribe: https://github.com/facebook/scribe
    * Facebook, 네이버 메일...
* 시간 단위
* 운영 측면에서 중요
    * 고객이 무언가를 물어보면 로그에서 뽑아내야함
    * 사용자가 얼마나 들어왔는지 확인
* 중앙 로그 서버등을 두고 실시간/시간 단위로 보냄
* 메일의 경우
    * 송신, 수신, 발송취소 등등 로그를 많이 해야함
## 백업도 중요
* 전체 백업을 할지, 변경분만 할지, ...
* DR(Disaster Recovery): 재난 대비용 백업

## 보관
### 얼마나 오랫동안 보관해야하나
* 정책의 문제: 전금법 관련 로그 12개월, 그 외 6개월
* 개인정보 같은 경우에는 짧게 유지해야함

## 조회
### 얼마나 많은 범위의 데이터를, 얼마나 빠르게
* 잘 구축하면 고객문의 처리를 비개발자에게 이관 가능

## 보안
### 개인 정보 저장하지 않도록
* 민감한 이슈
* 로그를 남길 때 익명화 처리(별표로 관리 하는 등) 해야함
    * 회원 서비스 같은 경우 ID/PW 남긴다던지 그러면 안됨
* 다루는 데이터 종류에 따라 정해야할 부분

# 품질 관리
## Java APM(Application Perfomance Monitoring)
### PINPOINT
* http://pinpoint.nhnent.com

### SCOUTER
* https://github.com/scouter-project/scouter
* 여유가 된다면 적용해보자

### NewRelic
* http://nenwrelic.com

## 디비
### ORM을 쓰지 않는다면, DBA의 쿼리 검수 필수
### 동적 쿼리를 없애도록
* 1개의 동적 쿼리는 생각보다 적은 N개의 정적 쿼리로 변경 가능
    * 쿼리 관리가 `용이`해지고
    * 각 정적 쿼리마다 힌트를 정확하게 줄 수 있음
    * 어떤 성능으로 어떤 결과를 낼 지 예측하기 쉬워짐


### `슬로우 쿼리 자동 검출`
* DBA 기준과 개발자 기준이 다를 수 있음. 반드시 협의!

## 로깅(앱, 웹)
### 에러 로그 수집에 Log&Crash 활용
* 모든 에러 통계
* 미해결 에러 통계

# 모니터링
## `경고와 장애 수준 분리`
### 대부분 장애 수준이 되고 나서야 알람을 받음
* 디스크 사용률 90%일 때 알람
    * "이제 장애 납니다"라는 문자 받는 것
    * 평상 시 사용률 20%를 유지하고 있다면, 90%가 아니라 50% 수준에서 경고 알람을 받아야 함
    * 각각의 케이스를 분리해서 알람을 해야 함

## `최저 값 모니터링`
### 보통 데몬 개수가 N개를 넘을 때만 알람을 받음
* 데몬이 죽었다면 알람 안 옴
* n개 이하일 때 알람을 줘야 함
* 양쪽 바운더리 다 점검 해야함

## `주기적으로 수치 점검`
### 시스템의 기능과 사용자 수는 계속 변함
* 경고, 장애, 최저 값 세 수치는 주기적으로 리뷰해야 함

## 테스트 활용하여 기능 체크
### 사용자 인터페이스 레벨의 테스트 모듈을 주기적으로 돌려, 서비스 상태 체크
* 두레이에는 주기적으로 업무를 만들어보거나, 하는 테스트가 있음
* 테스트를 자동화시켜 돌리면 사용자가 실제 경험하는 상황을 얻을 수 있음

## `무의미한 알람 받지 않도록`
### 무시해도 되는 알람이라면 받지 않도록 설정
* 그런 알람 속에 진짜 경고 메시지가 묻힐 수 있음
* 받아서 진짜 `처리`해야 할 것만 보낼 수 있도록
* 경고성 메시지는 하루에 한 번 모아서 보내던가 처리 바꾸기

## `연동 서비스 / 서버 모니터링`
### 외부 API를 이용할 경우, 해당 API를 직접 체크
* 연동 서비스쪽 원인으로 발생한 장애를 빠르게 검출할 수 있음
    * 보통 장애 상황에서 자기 서비스 영역을 주로 살펴보기 때문에 원인 파악하는 데 오래 걸림
    * 연동서비스의 응답 속도는 담당 서비스의 품질에도 영향을 줌
    * 내가 직접 관리하는 서비스가 아니라고 방치해서는 안 됨
* ex)ObjectStarage 사용 경우
    * 해당 서비스의 모니터링을 따로 함


# 시스템 유틸리티
## 필수
### vmstat, mpstat, iostat, ss(netstat), free, top, sar, ping
* 평상 시 사용법 숙지

# HTTP 에러 페이지 설정
## 50x
### 사용자들은 무의식적으로 새로 고침을 반복
* 의도치 않게 DDOS 공격
* 별도(정적) 서버로 리다이렉트 하도록 설정

# 흔한 장애
## `로그`
### DEBUG 레벨의 로깅
* 예) 로그 껐더니 속도가 10배 향상

### 에러 로그를 안 봐서 키우는 장애
* 에러 로그 크기는 0이 정상
* `괜찮은 에러`는 에러가 아니니 에러 로그에 남기지 말 것

## 타임아웃
### 디폴트 값 사용 주의
* 보통 디폴트가 얼마인지도 모르고 사용
* 보통 10ms로 응답할 때, 응답이 1초 지연되면 동시 접속수는 100배가 됨

### 평균 응답 속도에 상응하는 타임아웃 설정
* 보통 5ms 이하로 응답할 때, 타임아웃이 2초가 적당?
* 타임아웃을 빨리 내는 게 서비스를 보호하는게 도움이 됨

### 단위 확인 필요
* 예) ms인 줄 알고 1000이라고 넘겼는데... sec
* 코딩 네이밍 룰 같은게 중요(ex. timeout_ms, timeout_sec, ...)

## 에러 핸들링
### 소스코드에서 return 값 제대로 확인하지 않는 경우
* 실패인데 그 다음 코드를 계속 실행하는 경우
* 성공이 아니지만 굳이 실행을 멈출 필요가 없는데 리턴 하는 경우
    * 예) '최근 로그인 시각 업데이트'를 실패했다면 warn 레벨 로그를 남기고 그 다음 코드를 진행하는 것이 좋음

## `파일 / 디스크 관련`
### 디스크 가용량이 부족하거나
* 지우지 않고 쌓인 로그
    * 로그 로테이팅을 하면 디스크는 급격히 증가하지 않음

### inode가 부족하거나
* 작은 파일을 많이 저장하고 있을 때
    * ObjectStorage, 썸네일, ...
* 실제 용량이 많이 남아있는 데 가용 부족 메시지가 뜸

### FD_MAX가 작거나
* 트래픽 요청을 많이 받아야 하는 서비스를 받을 때
    * 다른 자원이 여유가 있지만 못받는 경우가 있음
* ulimit -n
    * 직접 확인해보자

## L4
### L4를 적용했는데도, 정상 동작하지 않은 서버로 계속 요청이 가는 경우
* HTTP라면 L7 헬스 체크 적용

## 디비
### 갑자기 쿼리의 실행 계획이 바뀌어 슬로우 쿼리 발생
* 쿼리에 힌트를 주어 실행 계획을 고정
    * 동적으로 문자열을 만들어 쿼리를 생성할 경우 힌트 주기가 어려움
    * 동적 쿼리를 다수의 정적 쿼리로!
    * [MYSQL 힌트](https://taes-k.github.io/2019/11/22/mysql-hint/)

### 통계 쿼리
* 캐쉬 메모리가 지역성이 떨어지는 데이터로 채워져 성능 저하 초래
    * 통계 작업이 빈번하다면 별도 슬레이브 서버를 두자

### 집계 쿼리
* 예) 받은 메일함의 안 읽은 메일 통 수 관리
    * 트래픽 증가 시 디비 부하 급증

## 배포 후
### 사용자 단에서 일괄 재구동
* 일순간에 사용자가 몰려드는 경우를 완화시켜야 함
* DDoS와 같은 서버 요청 발생. 특히 집계 쿼리
    * 클라이언트가 랜덤으로 재구동하도록 설계

## DNS
### JVM은 DNS 쿼리 결과 캐싱
* 기본 설정은 JVM 재구동하기 전 까지 캐싱 결과 변경 불가
* ```$JAVA_HOME/jre/lib/security/java.security``` 파일에서 설정 가능

# 기본 설정 
* 확인하고 수정할 필요가 있다면 적절히 수정해야 함
## NGiNX
### worker_connection

## ulimit
### 시스템에 따라 다름
* NGiNX worker_connection, Apache MaxClients에 영향을 줌


# 대규모 장애 대응(서비스 평행화)
## 중요 기능 우선
### 서비스 기능을 중요도로 정렬
* 게시판: 읽기 > 쓰기 > 검색
* 메일: 수신/읽기 > 목록 > ... > 쓰기 > ... > 검색 > 색인
    * 우리 서비스에서 제공 가능한 일 부터
* 검색: 통합검색 > ... > ... > 색인


### 장애 시 중요 기능을 보호하는 대응
* 우선 순위 떨어지는 기능을 포기하여 상위 기능 사용성을 유지
    * 예) 메일서비스에서는, API 서버가 매우 바쁠 때 
    * 웹서버의 요청은 모두 처리하지만 IMAP 서버에서의 요청 중 50%는 취소하는 식으로 조절 가능

## 기타
### 캐쉬 만료 기간 연장
* 캐쉬를 2분간 보관한다면 임시로 10분 등으로 연장
    * 백엔드 호출이 그만큼 줄어들게 됨

# 장애 대응
## `전파`
### 메일링 리스트를 이용하여 유관자에게 전파
* 장애 처리 전에 일단 전파(30초면 충분)
* 공유가 되지 않으면 의존하는 다른 서비스가 잘못된 대응을 할 수도 있음
    * 리소스 낭비

## 처리
### `Case By Case`
* 에러 로그
    * 평상 시에 에러 로그를 0으로 관리해야 도움이 됨
* 롤백이 가능하면 롤백
    * 사전에 롤백 준비를 해야 그나마 롤백도 빠르게 가능
* 에러의 원인이 내 서비스가 아닌 연관 API 서버에 있을 수도
    * 연관 서버의 서비스 모니터링을 하는 것도 중요

### 유용한 스크립트
* 특정 일시 N분간 접속한 IP를 빈도로 정렬
    * 그 결과를 각 IP별 접속한 URI
    * 일주일 전과 비교하면 트래픽 정상 여부를 구분할 수 있음
        * 요일마다 특성이 있으므로(월요일 아침의 메일 서비스, ...)

* 특정 일시 N분간 접속한 URI를 빈도로 정렬


# `장애 후 대응`
## 회고
### 기계적으로 할 일
* 개발 TC(xUnit...) 보강
* QA TC 보강


### 해서는 안되는 것
* 왜 TC에서 빼먹었어?
* 누가 실수? 장애 귀책 부서가 어디?

### 과거는 과거
* 원인을 찾아 다시 발생하지 않도록

### 빠른 장애 대처
* 장애를 어떻게 알았는가?
    * 모니터링 알람으로 안 것이 아니라면, 추가 등록
* 원인을 아는데 왜 오래 걸렸는지, 자동으로 알 수는 없었는지
    * 스크립트화: 스크립트 묶음을 장애 시 활용하면 원인 진단을 빠르게 할 수 있음
* 자동으로 복구할 수는 없었는가?

### 장애 예방
* 전조 증상은 없었는가? 그 시점에 알람을 받을 수는 없었는가?
    * 방법을 찾아내면 모니터링 항목으로 등록


---
참고: NHN 기술교육 - 안정적인 서비스 운영